{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "Lab_7_Exercise_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JALVITO/CE888/blob/master/Labs/Lab_7/Lab_7_Exercise_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwRGEQbzGpYQ"
      },
      "source": [
        "# First CNN model for MNIST Dataset\n",
        "\n",
        "* MNIST Dataset is ''Hello World'' of Image Recognition\n",
        "\n",
        "* [Dataset HomePage](http://yann.lecun.com/exdb/mnist/)\n",
        "\n",
        "* History of MNIST Dataset [Watch here](https://www.youtube.com/watch?v=oKzNUGz21JM)\n",
        "\n",
        "\n",
        "---\n",
        "The MNIST database of handwritten digits, available from this page, has a training set of 60,000 examples, and a \n",
        "test set of 10,000 examples. It is a subset of a larger set available from NIST. The digits have been size-normalized and centered in a fixed-size image.\n",
        "\n",
        "![Kitten](https://camo.githubusercontent.com/01c057a753e92a9bc70b8c45d62b295431851c09cffadf53106fc0aea7e2843f/687474703a2f2f692e7974696d672e636f6d2f76692f3051493378675875422d512f687164656661756c742e6a7067)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhmJOHCpJD_w"
      },
      "source": [
        "# Let's start building our first CNN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSyHCSV7jymI"
      },
      "source": [
        "from keras import layers\n",
        "from keras import models"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWNzCYUUjymN"
      },
      "source": [
        "Importantly, a convnet takes as input tensors of shape (image_height, image_width,\n",
        "image_channels) (not including the batch dimension). In this case, we’ll configure\n",
        "the convnet to process inputs of size (28, 28, 1), which is the format of MNIST\n",
        "images. We’ll do this by passing the argument input_shape=(28, 28, 1) to the first\n",
        "layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dM4JLEpwjymN"
      },
      "source": [
        "#### Instantiating a small convnet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-OnpExGjymO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38f5a6b8-86b1-4b6f-c0fb-82574266be58"
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.summary()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 3, 3, 64)          36928     \n",
            "=================================================================\n",
            "Total params: 55,744\n",
            "Trainable params: 55,744\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gcVG3xkjymR"
      },
      "source": [
        "#### Adding a classifier on top of the convnet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2DfhDJYjymR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b2e2215-d189-43e5-c714-eaaae8729bd1"
      },
      "source": [
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 3, 3, 64)          36928     \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 576)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                36928     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 93,322\n",
            "Trainable params: 93,322\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOKVF4nKjymU"
      },
      "source": [
        "### Training the convnet on MNIST images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIcgUbbUjymV"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "from keras.utils import to_categorical"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnJ2Pfs_jymX"
      },
      "source": [
        "#### Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpHGHE9MjymY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4abdb0f-d9e5-47eb-9993-94176c257556"
      },
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "train_images = train_images.reshape((60000, 28, 28, 1))\n",
        "train_images = train_images.astype('float32') / 255\n",
        "test_images = test_images.reshape((10000, 28, 28, 1))\n",
        "test_images = test_images.astype('float32') / 255\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HoTLrfSjymd"
      },
      "source": [
        "#### compile and fit model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i23FDtC9jyme",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69eecdbd-e780-454e-b31b-fd71496ce779"
      },
      "source": [
        "model.compile(optimizer='rmsprop', \n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "history = model.fit(train_images, train_labels, epochs=5, batch_size=64, validation_split=0.2)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "750/750 [==============================] - 45s 58ms/step - loss: 0.4519 - accuracy: 0.8544 - val_loss: 0.0608 - val_accuracy: 0.9817\n",
            "Epoch 2/5\n",
            "750/750 [==============================] - 44s 58ms/step - loss: 0.0574 - accuracy: 0.9824 - val_loss: 0.0506 - val_accuracy: 0.9856\n",
            "Epoch 3/5\n",
            "750/750 [==============================] - 44s 58ms/step - loss: 0.0350 - accuracy: 0.9884 - val_loss: 0.0506 - val_accuracy: 0.9850\n",
            "Epoch 4/5\n",
            "750/750 [==============================] - 43s 58ms/step - loss: 0.0275 - accuracy: 0.9916 - val_loss: 0.0404 - val_accuracy: 0.9894\n",
            "Epoch 5/5\n",
            "750/750 [==============================] - 43s 58ms/step - loss: 0.0203 - accuracy: 0.9937 - val_loss: 0.0519 - val_accuracy: 0.9863\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zU8iI5ojymg"
      },
      "source": [
        "#### evaluate model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3VeaL1Njymh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5074f3dc-c2a1-45a1-a1e4-c21c5f11493c"
      },
      "source": [
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "test_acc"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 3s 10ms/step - loss: 0.0427 - accuracy: 0.9877\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9876999855041504"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXNZOY7Sjymj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "ff595f52-2d6c-4869-88fc-19909b1184d6"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsQMc0Iojyml"
      },
      "source": [
        "## Task 1\n",
        "\n",
        "Change the activation function and other parameters such as optimizer to see the effect on the network and it's performance. If possible create a grid search. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owJ-29BrJXNa"
      },
      "source": [
        "def create_model(optimizer='Adam', activation='relu'):\n",
        "  model = models.Sequential()\n",
        "\n",
        "  # ConvNet\n",
        "  model.add(layers.Conv2D(32, (3, 3), activation=activation, input_shape=(28, 28, 1)))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.Conv2D(64, (3, 3), activation=activation))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.Conv2D(64, (3, 3), activation=activation))\n",
        "\n",
        "  # Classifier\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(64, activation=activation))\n",
        "  model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "  model.compile(optimizer=optimizer, \n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nb0ftB4A2ArU",
        "outputId": "c5f65138-09ca-4d0f-90ff-d8a81cdeda44"
      },
      "source": [
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "batch_size = [64, 128]\n",
        "optimizer = ['RMSprop', 'Adam']\n",
        "activation = ['relu', 'sigmoid']\n",
        "param_grid = dict(batch_size=batch_size, optimizer=optimizer, activation=activation)\n",
        "\n",
        "model = KerasClassifier(build_fn=create_model, epochs=5)\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, verbose=1)\n",
        "grid_result = grid.fit(train_images, train_labels)\n",
        "\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
            "Epoch 1/5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "750/750 [==============================] - 42s 55ms/step - loss: 0.4395 - accuracy: 0.8590\n",
            "Epoch 2/5\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 0.0557 - accuracy: 0.9825\n",
            "Epoch 3/5\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 0.0405 - accuracy: 0.9870\n",
            "Epoch 4/5\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 0.0281 - accuracy: 0.9909\n",
            "Epoch 5/5\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 0.0202 - accuracy: 0.9934\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0395 - accuracy: 0.9896\n",
            "Epoch 1/5\n",
            "750/750 [==============================] - 42s 54ms/step - loss: 0.4339 - accuracy: 0.8592\n",
            "Epoch 2/5\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 0.0554 - accuracy: 0.9823\n",
            "Epoch 3/5\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 0.0369 - accuracy: 0.9883\n",
            "Epoch 4/5\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 0.0264 - accuracy: 0.9913\n",
            "Epoch 5/5\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 0.0222 - accuracy: 0.9928\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0310 - accuracy: 0.9903\n",
            "Epoch 1/5\n",
            "750/750 [==============================] - 50s 66ms/step - loss: 0.4463 - accuracy: 0.8515\n",
            "Epoch 2/5\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 0.0567 - accuracy: 0.9822\n",
            "Epoch 3/5\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 0.0369 - accuracy: 0.9887\n",
            "Epoch 4/5\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 0.0244 - accuracy: 0.9924\n",
            "Epoch 5/5\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 0.0200 - accuracy: 0.9939\n",
            "188/188 [==============================] - 4s 18ms/step - loss: 0.0454 - accuracy: 0.9880\n",
            "Epoch 1/5\n",
            "750/750 [==============================] - 43s 55ms/step - loss: 0.4159 - accuracy: 0.8666\n",
            "Epoch 2/5\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 0.0536 - accuracy: 0.9828\n",
            "Epoch 3/5\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 0.0341 - accuracy: 0.9891\n",
            "Epoch 4/5\n",
            "750/750 [==============================] - 42s 56ms/step - loss: 0.0260 - accuracy: 0.9921\n",
            "Epoch 5/5\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 0.0200 - accuracy: 0.9937\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0490 - accuracy: 0.9858\n",
            "Epoch 1/5\n",
            "750/750 [==============================] - 42s 55ms/step - loss: 0.4734 - accuracy: 0.8454\n",
            "Epoch 2/5\n",
            "750/750 [==============================] - 42s 56ms/step - loss: 0.0576 - accuracy: 0.9820\n",
            "Epoch 3/5\n",
            "750/750 [==============================] - 42s 56ms/step - loss: 0.0362 - accuracy: 0.9886\n",
            "Epoch 4/5\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 0.0270 - accuracy: 0.9918\n",
            "Epoch 5/5\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 0.0210 - accuracy: 0.9935\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0430 - accuracy: 0.9893\n",
            "Epoch 1/5\n",
            "750/750 [==============================] - 43s 57ms/step - loss: 0.4794 - accuracy: 0.8584\n",
            "Epoch 2/5\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 0.0606 - accuracy: 0.9804\n",
            "Epoch 3/5\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 0.0378 - accuracy: 0.9873\n",
            "Epoch 4/5\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 0.0286 - accuracy: 0.9902\n",
            "Epoch 5/5\n",
            "750/750 [==============================] - 42s 55ms/step - loss: 0.0212 - accuracy: 0.9932\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0344 - accuracy: 0.9901\n",
            "Epoch 1/5\n",
            "750/750 [==============================] - 42s 55ms/step - loss: 0.4622 - accuracy: 0.8524\n",
            "Epoch 2/5\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 0.0602 - accuracy: 0.9811\n",
            "Epoch 3/5\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 0.0403 - accuracy: 0.9868\n",
            "Epoch 4/5\n",
            "750/750 [==============================] - 42s 56ms/step - loss: 0.0279 - accuracy: 0.9910\n",
            "Epoch 5/5\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 0.0254 - accuracy: 0.9920\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0373 - accuracy: 0.9886\n",
            "Epoch 1/5\n",
            "750/750 [==============================] - 42s 55ms/step - loss: 0.4665 - accuracy: 0.8600\n",
            "Epoch 2/5\n",
            "750/750 [==============================] - 42s 56ms/step - loss: 0.0580 - accuracy: 0.9822\n",
            "Epoch 3/5\n",
            "750/750 [==============================] - 42s 56ms/step - loss: 0.0379 - accuracy: 0.9877\n",
            "Epoch 4/5\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 0.0294 - accuracy: 0.9911\n",
            "Epoch 5/5\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 0.0203 - accuracy: 0.9930\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0376 - accuracy: 0.9884\n",
            "Epoch 1/5\n",
            "750/750 [==============================] - 42s 56ms/step - loss: 0.4887 - accuracy: 0.8485\n",
            "Epoch 2/5\n",
            "750/750 [==============================] - 42s 55ms/step - loss: 0.0617 - accuracy: 0.9813\n",
            "Epoch 3/5\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 0.0418 - accuracy: 0.9870\n",
            "Epoch 4/5\n",
            "750/750 [==============================] - 53s 71ms/step - loss: 0.0330 - accuracy: 0.9903\n",
            "Epoch 5/5\n",
            "750/750 [==============================] - 42s 56ms/step - loss: 0.0226 - accuracy: 0.9925\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0625 - accuracy: 0.9819\n",
            "Epoch 1/5\n",
            "750/750 [==============================] - 43s 55ms/step - loss: 0.4947 - accuracy: 0.8470\n",
            "Epoch 2/5\n",
            "750/750 [==============================] - 42s 55ms/step - loss: 0.0601 - accuracy: 0.9819\n",
            "Epoch 3/5\n",
            "750/750 [==============================] - 42s 56ms/step - loss: 0.0400 - accuracy: 0.9870\n",
            "Epoch 4/5\n",
            "750/750 [==============================] - 42s 56ms/step - loss: 0.0311 - accuracy: 0.9898\n",
            "Epoch 5/5\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 0.0218 - accuracy: 0.9929\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0378 - accuracy: 0.9896\n",
            "Epoch 1/5\n",
            "375/375 [==============================] - 39s 101ms/step - loss: 0.5953 - accuracy: 0.8129\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 38s 102ms/step - loss: 0.0734 - accuracy: 0.9776\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 37s 100ms/step - loss: 0.0445 - accuracy: 0.9869\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 37s 99ms/step - loss: 0.0320 - accuracy: 0.9896\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 37s 100ms/step - loss: 0.0241 - accuracy: 0.9921\n",
            "94/94 [==============================] - 3s 31ms/step - loss: 0.0450 - accuracy: 0.9874\n",
            "Epoch 1/5\n",
            "375/375 [==============================] - 39s 101ms/step - loss: 0.5826 - accuracy: 0.8183\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 39s 103ms/step - loss: 0.0766 - accuracy: 0.9764\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 37s 100ms/step - loss: 0.0411 - accuracy: 0.9872\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 38s 100ms/step - loss: 0.0317 - accuracy: 0.9902\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 38s 101ms/step - loss: 0.0239 - accuracy: 0.9925\n",
            "94/94 [==============================] - 3s 29ms/step - loss: 0.0360 - accuracy: 0.9887\n",
            "Epoch 1/5\n",
            "375/375 [==============================] - 39s 103ms/step - loss: 0.6057 - accuracy: 0.8030\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 38s 102ms/step - loss: 0.0717 - accuracy: 0.9790\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 38s 101ms/step - loss: 0.0442 - accuracy: 0.9860\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 38s 100ms/step - loss: 0.0314 - accuracy: 0.9906\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 38s 102ms/step - loss: 0.0218 - accuracy: 0.9931\n",
            "94/94 [==============================] - 3s 31ms/step - loss: 0.0566 - accuracy: 0.9837\n",
            "Epoch 1/5\n",
            "375/375 [==============================] - 39s 101ms/step - loss: 0.5738 - accuracy: 0.8162\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 38s 100ms/step - loss: 0.0672 - accuracy: 0.9805\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 38s 102ms/step - loss: 0.0394 - accuracy: 0.9875\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 37s 100ms/step - loss: 0.0329 - accuracy: 0.9895\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 38s 100ms/step - loss: 0.0212 - accuracy: 0.9931\n",
            "94/94 [==============================] - 3s 30ms/step - loss: 0.0404 - accuracy: 0.9876\n",
            "Epoch 1/5\n",
            "375/375 [==============================] - 38s 101ms/step - loss: 0.5546 - accuracy: 0.8235\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 38s 101ms/step - loss: 0.0675 - accuracy: 0.9789\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 38s 103ms/step - loss: 0.0418 - accuracy: 0.9873\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 39s 105ms/step - loss: 0.0303 - accuracy: 0.9903\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 38s 100ms/step - loss: 0.0238 - accuracy: 0.9925\n",
            "94/94 [==============================] - 3s 30ms/step - loss: 0.0459 - accuracy: 0.9872\n",
            "Epoch 1/5\n",
            "375/375 [==============================] - 39s 102ms/step - loss: 0.6294 - accuracy: 0.8119\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 37s 100ms/step - loss: 0.0765 - accuracy: 0.9765\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 38s 100ms/step - loss: 0.0492 - accuracy: 0.9841\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 38s 100ms/step - loss: 0.0337 - accuracy: 0.9890\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 37s 100ms/step - loss: 0.0269 - accuracy: 0.9919\n",
            "94/94 [==============================] - 3s 30ms/step - loss: 0.0428 - accuracy: 0.9877\n",
            "Epoch 1/5\n",
            "375/375 [==============================] - 40s 103ms/step - loss: 0.6264 - accuracy: 0.8216\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 38s 103ms/step - loss: 0.0741 - accuracy: 0.9775\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 38s 102ms/step - loss: 0.0466 - accuracy: 0.9857\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 39s 103ms/step - loss: 0.0400 - accuracy: 0.9875\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 39s 103ms/step - loss: 0.0260 - accuracy: 0.9924\n",
            "94/94 [==============================] - 3s 30ms/step - loss: 0.0307 - accuracy: 0.9898\n",
            "Epoch 1/5\n",
            "375/375 [==============================] - 39s 101ms/step - loss: 0.6163 - accuracy: 0.8201\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 38s 100ms/step - loss: 0.0771 - accuracy: 0.9750\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 38s 100ms/step - loss: 0.0483 - accuracy: 0.9842\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 37s 100ms/step - loss: 0.0369 - accuracy: 0.9887\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 38s 101ms/step - loss: 0.0295 - accuracy: 0.9907\n",
            "94/94 [==============================] - 3s 31ms/step - loss: 0.0413 - accuracy: 0.9871\n",
            "Epoch 1/5\n",
            "375/375 [==============================] - 40s 104ms/step - loss: 0.6344 - accuracy: 0.8097\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 40s 107ms/step - loss: 0.0711 - accuracy: 0.9787\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 39s 103ms/step - loss: 0.0530 - accuracy: 0.9833\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 39s 104ms/step - loss: 0.0344 - accuracy: 0.9897\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 39s 103ms/step - loss: 0.0261 - accuracy: 0.9911\n",
            "94/94 [==============================] - 3s 29ms/step - loss: 0.0450 - accuracy: 0.9856\n",
            "Epoch 1/5\n",
            "375/375 [==============================] - 38s 101ms/step - loss: 0.6334 - accuracy: 0.8036\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 38s 101ms/step - loss: 0.0732 - accuracy: 0.9763\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 38s 101ms/step - loss: 0.0437 - accuracy: 0.9870\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 38s 103ms/step - loss: 0.0331 - accuracy: 0.9899\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 38s 101ms/step - loss: 0.0286 - accuracy: 0.9907\n",
            "94/94 [==============================] - 3s 30ms/step - loss: 0.0408 - accuracy: 0.9877\n",
            "Epoch 1/5\n",
            "750/750 [==============================] - 44s 57ms/step - loss: 1.7585 - accuracy: 0.3650\n",
            "Epoch 2/5\n",
            "750/750 [==============================] - 43s 57ms/step - loss: 0.2400 - accuracy: 0.9302\n",
            "Epoch 3/5\n",
            "750/750 [==============================] - 42s 56ms/step - loss: 0.1228 - accuracy: 0.9629\n",
            "Epoch 4/5\n",
            "750/750 [==============================] - 42s 57ms/step - loss: 0.0900 - accuracy: 0.9730\n",
            "Epoch 5/5\n",
            "750/750 [==============================] - 42s 56ms/step - loss: 0.0645 - accuracy: 0.9797\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0779 - accuracy: 0.9763\n",
            "Epoch 1/5\n",
            "750/750 [==============================] - 45s 59ms/step - loss: 1.7309 - accuracy: 0.3812\n",
            "Epoch 2/5\n",
            "750/750 [==============================] - 43s 58ms/step - loss: 0.2518 - accuracy: 0.9268\n",
            "Epoch 3/5\n",
            "750/750 [==============================] - 43s 57ms/step - loss: 0.1340 - accuracy: 0.9594\n",
            "Epoch 4/5\n",
            "750/750 [==============================] - 43s 57ms/step - loss: 0.0907 - accuracy: 0.9722\n",
            "Epoch 5/5\n",
            "750/750 [==============================] - 42s 56ms/step - loss: 0.0752 - accuracy: 0.9770\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0656 - accuracy: 0.9789\n",
            "Epoch 1/5\n",
            "750/750 [==============================] - 43s 57ms/step - loss: 1.6509 - accuracy: 0.4212\n",
            "Epoch 2/5\n",
            "750/750 [==============================] - 55s 73ms/step - loss: 0.2543 - accuracy: 0.9260\n",
            "Epoch 3/5\n",
            "750/750 [==============================] - 43s 57ms/step - loss: 0.1329 - accuracy: 0.9612\n",
            "Epoch 4/5\n",
            "750/750 [==============================] - 43s 57ms/step - loss: 0.0912 - accuracy: 0.9727\n",
            "Epoch 5/5\n",
            "750/750 [==============================] - 42s 56ms/step - loss: 0.0724 - accuracy: 0.9774\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0767 - accuracy: 0.9773\n",
            "Epoch 1/5\n",
            "750/750 [==============================] - 44s 57ms/step - loss: 1.6815 - accuracy: 0.4074\n",
            "Epoch 2/5\n",
            "750/750 [==============================] - 43s 57ms/step - loss: 0.2260 - accuracy: 0.9344\n",
            "Epoch 3/5\n",
            "750/750 [==============================] - 43s 57ms/step - loss: 0.1209 - accuracy: 0.9623\n",
            "Epoch 4/5\n",
            "750/750 [==============================] - 43s 57ms/step - loss: 0.0828 - accuracy: 0.9751\n",
            "Epoch 5/5\n",
            "750/750 [==============================] - 43s 57ms/step - loss: 0.0691 - accuracy: 0.9785\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0736 - accuracy: 0.9762\n",
            "Epoch 1/5\n",
            "750/750 [==============================] - 45s 58ms/step - loss: 1.6967 - accuracy: 0.4001\n",
            "Epoch 2/5\n",
            "750/750 [==============================] - 42s 57ms/step - loss: 0.2606 - accuracy: 0.9223\n",
            "Epoch 3/5\n",
            "750/750 [==============================] - 42s 57ms/step - loss: 0.1310 - accuracy: 0.9600\n",
            "Epoch 4/5\n",
            "750/750 [==============================] - 43s 57ms/step - loss: 0.0951 - accuracy: 0.9710\n",
            "Epoch 5/5\n",
            "750/750 [==============================] - 43s 57ms/step - loss: 0.0713 - accuracy: 0.9775\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0679 - accuracy: 0.9786\n",
            "Epoch 1/5\n",
            "750/750 [==============================] - 42s 55ms/step - loss: 1.7391 - accuracy: 0.3752\n",
            "Epoch 2/5\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 0.2052 - accuracy: 0.9429\n",
            "Epoch 3/5\n",
            "750/750 [==============================] - 43s 57ms/step - loss: 0.1110 - accuracy: 0.9674\n",
            "Epoch 4/5\n",
            "750/750 [==============================] - 42s 56ms/step - loss: 0.0810 - accuracy: 0.9754\n",
            "Epoch 5/5\n",
            "750/750 [==============================] - 42s 56ms/step - loss: 0.0654 - accuracy: 0.9816\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0654 - accuracy: 0.9817\n",
            "Epoch 1/5\n",
            "750/750 [==============================] - 42s 56ms/step - loss: 1.7476 - accuracy: 0.3685\n",
            "Epoch 2/5\n",
            "750/750 [==============================] - 42s 55ms/step - loss: 0.2103 - accuracy: 0.9425\n",
            "Epoch 3/5\n",
            "750/750 [==============================] - 42s 56ms/step - loss: 0.1156 - accuracy: 0.9678\n",
            "Epoch 4/5\n",
            "750/750 [==============================] - 42s 56ms/step - loss: 0.0816 - accuracy: 0.9767\n",
            "Epoch 5/5\n",
            "750/750 [==============================] - 42s 56ms/step - loss: 0.0637 - accuracy: 0.9810\n",
            "188/188 [==============================] - 4s 18ms/step - loss: 0.0623 - accuracy: 0.9805\n",
            "Epoch 1/5\n",
            "750/750 [==============================] - 43s 56ms/step - loss: 1.7739 - accuracy: 0.3669\n",
            "Epoch 2/5\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 0.2406 - accuracy: 0.9320\n",
            "Epoch 3/5\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 0.1286 - accuracy: 0.9636\n",
            "Epoch 4/5\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 0.0927 - accuracy: 0.9721\n",
            "Epoch 5/5\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 0.0712 - accuracy: 0.9790\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0730 - accuracy: 0.9787\n",
            "Epoch 1/5\n",
            "750/750 [==============================] - 42s 56ms/step - loss: 1.7278 - accuracy: 0.3808\n",
            "Epoch 2/5\n",
            "750/750 [==============================] - 42s 57ms/step - loss: 0.2041 - accuracy: 0.9453\n",
            "Epoch 3/5\n",
            "750/750 [==============================] - 42s 56ms/step - loss: 0.1141 - accuracy: 0.9672\n",
            "Epoch 4/5\n",
            "750/750 [==============================] - 42s 56ms/step - loss: 0.0779 - accuracy: 0.9778\n",
            "Epoch 5/5\n",
            "750/750 [==============================] - 42s 56ms/step - loss: 0.0637 - accuracy: 0.9802\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0668 - accuracy: 0.9796\n",
            "Epoch 1/5\n",
            "750/750 [==============================] - 43s 56ms/step - loss: 1.7226 - accuracy: 0.3821\n",
            "Epoch 2/5\n",
            "750/750 [==============================] - 42s 56ms/step - loss: 0.2078 - accuracy: 0.9447\n",
            "Epoch 3/5\n",
            "750/750 [==============================] - 42s 57ms/step - loss: 0.1170 - accuracy: 0.9669\n",
            "Epoch 4/5\n",
            "750/750 [==============================] - 43s 57ms/step - loss: 0.0804 - accuracy: 0.9770\n",
            "Epoch 5/5\n",
            "750/750 [==============================] - 43s 57ms/step - loss: 0.0627 - accuracy: 0.9807\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.0603 - accuracy: 0.9821\n",
            "Epoch 1/5\n",
            "375/375 [==============================] - 38s 100ms/step - loss: 2.0087 - accuracy: 0.2737\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 37s 98ms/step - loss: 0.4024 - accuracy: 0.8885\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 37s 98ms/step - loss: 0.2152 - accuracy: 0.9360\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 37s 99ms/step - loss: 0.1405 - accuracy: 0.9583\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 37s 99ms/step - loss: 0.1031 - accuracy: 0.9676\n",
            "94/94 [==============================] - 3s 30ms/step - loss: 0.0971 - accuracy: 0.9693\n",
            "Epoch 1/5\n",
            "375/375 [==============================] - 41s 105ms/step - loss: 2.0254 - accuracy: 0.2597\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 39s 105ms/step - loss: 0.4066 - accuracy: 0.8886\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 39s 104ms/step - loss: 0.2058 - accuracy: 0.9392\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 40s 106ms/step - loss: 0.1352 - accuracy: 0.9603\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 39s 105ms/step - loss: 0.1038 - accuracy: 0.9686\n",
            "94/94 [==============================] - 3s 31ms/step - loss: 0.0871 - accuracy: 0.9729\n",
            "Epoch 1/5\n",
            "375/375 [==============================] - 38s 100ms/step - loss: 1.9886 - accuracy: 0.2880\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 37s 99ms/step - loss: 0.4222 - accuracy: 0.8796\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 37s 99ms/step - loss: 0.2164 - accuracy: 0.9362\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 37s 99ms/step - loss: 0.1421 - accuracy: 0.9581\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 37s 100ms/step - loss: 0.1096 - accuracy: 0.9671\n",
            "94/94 [==============================] - 3s 31ms/step - loss: 0.1074 - accuracy: 0.9664\n",
            "Epoch 1/5\n",
            "375/375 [==============================] - 38s 99ms/step - loss: 1.9948 - accuracy: 0.2765\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 38s 100ms/step - loss: 0.3879 - accuracy: 0.8930\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 39s 105ms/step - loss: 0.1961 - accuracy: 0.9416\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 37s 99ms/step - loss: 0.1311 - accuracy: 0.9616\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 37s 99ms/step - loss: 0.0944 - accuracy: 0.9711\n",
            "94/94 [==============================] - 3s 31ms/step - loss: 0.0926 - accuracy: 0.9724\n",
            "Epoch 1/5\n",
            "375/375 [==============================] - 38s 100ms/step - loss: 2.0601 - accuracy: 0.2432\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 37s 99ms/step - loss: 0.4739 - accuracy: 0.8697\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 38s 101ms/step - loss: 0.2508 - accuracy: 0.9272\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 37s 100ms/step - loss: 0.1536 - accuracy: 0.9539\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 38s 100ms/step - loss: 0.1120 - accuracy: 0.9657\n",
            "94/94 [==============================] - 3s 31ms/step - loss: 0.0869 - accuracy: 0.9737\n",
            "Epoch 1/5\n",
            "375/375 [==============================] - 38s 100ms/step - loss: 2.1324 - accuracy: 0.2086\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 37s 98ms/step - loss: 0.3773 - accuracy: 0.9043\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 37s 97ms/step - loss: 0.1774 - accuracy: 0.9517\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 37s 98ms/step - loss: 0.1218 - accuracy: 0.9664\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 37s 98ms/step - loss: 0.0921 - accuracy: 0.9743\n",
            "94/94 [==============================] - 3s 30ms/step - loss: 0.0846 - accuracy: 0.9760\n",
            "Epoch 1/5\n",
            "375/375 [==============================] - 38s 99ms/step - loss: 2.0581 - accuracy: 0.2402\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 37s 98ms/step - loss: 0.3497 - accuracy: 0.9102\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 37s 98ms/step - loss: 0.1780 - accuracy: 0.9517\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 37s 98ms/step - loss: 0.1220 - accuracy: 0.9644\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 38s 102ms/step - loss: 0.0907 - accuracy: 0.9736\n",
            "94/94 [==============================] - 3s 30ms/step - loss: 0.0836 - accuracy: 0.9751\n",
            "Epoch 1/5\n",
            "375/375 [==============================] - 37s 98ms/step - loss: 2.0924 - accuracy: 0.2236\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 37s 97ms/step - loss: 0.3637 - accuracy: 0.9045\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 37s 98ms/step - loss: 0.1772 - accuracy: 0.9520\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 37s 98ms/step - loss: 0.1244 - accuracy: 0.9641\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 37s 98ms/step - loss: 0.0901 - accuracy: 0.9742\n",
            "94/94 [==============================] - 3s 30ms/step - loss: 0.0814 - accuracy: 0.9762\n",
            "Epoch 1/5\n",
            "375/375 [==============================] - 38s 99ms/step - loss: 2.0375 - accuracy: 0.2555\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 37s 98ms/step - loss: 0.3405 - accuracy: 0.9099\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 37s 99ms/step - loss: 0.1722 - accuracy: 0.9524\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 37s 98ms/step - loss: 0.1131 - accuracy: 0.9685\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 37s 98ms/step - loss: 0.0917 - accuracy: 0.9731\n",
            "94/94 [==============================] - 3s 30ms/step - loss: 0.0935 - accuracy: 0.9722\n",
            "Epoch 1/5\n",
            "375/375 [==============================] - 40s 103ms/step - loss: 2.0680 - accuracy: 0.2336\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 39s 103ms/step - loss: 0.3731 - accuracy: 0.9037\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 39s 104ms/step - loss: 0.1922 - accuracy: 0.9460\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 39s 103ms/step - loss: 0.1225 - accuracy: 0.9657\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 39s 104ms/step - loss: 0.0909 - accuracy: 0.9733\n",
            "94/94 [==============================] - 3s 31ms/step - loss: 0.0810 - accuracy: 0.9771\n",
            "Epoch 1/5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  40 out of  40 | elapsed: 136.0min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "938/938 [==============================] - 54s 57ms/step - loss: 0.4227 - accuracy: 0.8666\n",
            "Epoch 2/5\n",
            "938/938 [==============================] - 52s 56ms/step - loss: 0.0494 - accuracy: 0.9835\n",
            "Epoch 3/5\n",
            "938/938 [==============================] - 53s 56ms/step - loss: 0.0326 - accuracy: 0.9901\n",
            "Epoch 4/5\n",
            "938/938 [==============================] - 52s 56ms/step - loss: 0.0248 - accuracy: 0.9924\n",
            "Epoch 5/5\n",
            "938/938 [==============================] - 52s 55ms/step - loss: 0.0182 - accuracy: 0.9940\n",
            "Best: 0.988617 using {'activation': 'relu', 'batch_size': 64, 'optimizer': 'RMSprop'}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}